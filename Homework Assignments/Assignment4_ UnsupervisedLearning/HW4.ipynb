{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9f2dd8d0",
      "metadata": {
        "id": "9f2dd8d0"
      },
      "source": [
        "\n",
        "# HW4\n",
        "\n",
        "**Scope:** Warm‑up → K‑Means → choosing *k* → DBSCAN → Hierarchical → compare.  \n",
        "**Dataset:** Iris (built‑in).  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e9eb627",
      "metadata": {
        "id": "3e9eb627"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Setup\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
        "\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (6,4)\n",
        "np.random.seed(0)\n",
        "print(\"✅ Environment ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "28KqV7ybtD4J"
      },
      "id": "28KqV7ybtD4J"
    },
    {
      "cell_type": "markdown",
      "id": "96814bbc",
      "metadata": {
        "id": "96814bbc"
      },
      "source": [
        "\n",
        "## Part 1: Warm‑up: Load, Scale, and Inspect\n",
        "\n",
        "**Why scaling?** Distance‑based algorithms (K‑Means, DBSCAN with Euclidean metric, Ward’s hierarchical) can be dominated by features with larger numeric ranges.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b20482b9",
      "metadata": {
        "id": "b20482b9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load Iris\n",
        "iris = load_iris(as_frame=True)\n",
        "X_df = iris.data.copy()     # DataFrame for readability\n",
        "y = iris.target.values      # labels for optional ARI\n",
        "\n",
        "display(X_df.describe())\n",
        "print(\"Shape:\", X_df.shape)\n",
        "print(\"Features:\", list(X_df.columns))\n",
        "\n",
        "# Standardize for algorithms\n",
        "scaler = StandardScaler().fit(X_df.values)\n",
        "X = scaler.transform(X_df.values)\n",
        "\n",
        "# We'll use two raw features for simple 2D plots (no PCA)\n",
        "feat_x, feat_y = \"petal length (cm)\", \"petal width (cm)\"\n",
        "ix, iy = list(X_df.columns).index(feat_x), list(X_df.columns).index(feat_y)\n",
        "\n",
        "# Quick 2D scatter in raw (unscaled) coordinates for intuition\n",
        "plt.scatter(X_df.iloc[:, ix], X_df.iloc[:, iy], s=20)\n",
        "plt.xlabel(feat_x); plt.ylabel(feat_y); plt.title(\"Raw feature view (unscaled)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90d14100",
      "metadata": {
        "id": "90d14100"
      },
      "source": [
        "\n",
        "**Q1:** Explain why scaling features can change the result of distance‑based clustering. Give one concrete failure mode if you **skip** scaling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ea35fef",
      "metadata": {
        "id": "7ea35fef"
      },
      "source": [
        "\n",
        "## Part 2: K‑Means (k = 3)\n",
        "\n",
        "- **K‑Means** groups points by minimizing within‑cluster squared distances.  \n",
        "- **Inertia**: sum of squared distances to the assigned centroid (↓ is better, but always decreases as k↑).  \n",
        "- **Silhouette**: (b − a) / max(a, b) where *a* is mean intra‑cluster distance, *b* is mean distance to nearest other cluster. Ranges \\[-1, 1\\]; higher is better.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e792ec99",
      "metadata": {
        "id": "e792ec99"
      },
      "outputs": [],
      "source": [
        "\n",
        "km3 = KMeans(n_clusters=3, n_init=10, random_state=0).fit(X)\n",
        "labels3 = km3.labels_\n",
        "sil3 = silhouette_score(X, labels3)\n",
        "\n",
        "# Visualize using two raw features; color by K-Means labels\n",
        "plt.scatter(X_df.iloc[:, ix], X_df.iloc[:, iy], c=labels3, s=20)\n",
        "plt.xlabel(feat_x); plt.ylabel(feat_y)\n",
        "plt.title(f\"K-Means (k=3) on scaled data — silhouette={sil3:.3f}\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Inertia (k=3): {km3.inertia_:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e307a026",
      "metadata": {
        "id": "e307a026"
      },
      "source": [
        "\n",
        "**Q2:** What does a **high** silhouette imply about cohesion and separation? Why might the 2D scatter above look clean while the silhouette is mediocre?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae20804c",
      "metadata": {
        "id": "ae20804c"
      },
      "source": [
        "\n",
        "## Part 3: Choosing the Number of Clusters *k* (Elbow + Silhouette)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db90ece2",
      "metadata": {
        "id": "db90ece2"
      },
      "outputs": [],
      "source": [
        "\n",
        "ks = range(2, 7)\n",
        "inertias, sils = [], []\n",
        "\n",
        "for k in ks:\n",
        "    km = KMeans(n_clusters=k, n_init=10, random_state=0).fit(X)\n",
        "    labels = km.labels_\n",
        "    inertias.append(km.inertia_)\n",
        "    sils.append(silhouette_score(X, labels))\n",
        "\n",
        "# Plot elbow\n",
        "plt.plot(list(ks), inertias, marker='o')\n",
        "plt.xlabel(\"k\"); plt.ylabel(\"Inertia (lower is better)\")\n",
        "plt.title(\"Elbow: Inertia vs k\")\n",
        "plt.show()\n",
        "\n",
        "# Plot silhouette\n",
        "plt.plot(list(ks), sils, marker='o')\n",
        "plt.xlabel(\"k\"); plt.ylabel(\"Silhouette (higher is better)\")\n",
        "plt.title(\"Silhouette vs k\")\n",
        "plt.show()\n",
        "\n",
        "print(\"k  | inertia     | silhouette\")\n",
        "for k, inn, si in zip(ks, inertias, sils):\n",
        "    print(f\"{k:<3}| {inn:<11.2f}| {si:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3328876f",
      "metadata": {
        "id": "3328876f"
      },
      "source": [
        "\n",
        "**Q3:** Pick a **k** you find reasonable and justify it using both plots. If your choice differs from the highest‑silhouette value, explain why.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91c2f582",
      "metadata": {
        "id": "91c2f582"
      },
      "source": [
        "\n",
        "## Part 4: Density‑Based Clustering with DBSCAN\n",
        "\n",
        "**DBSCAN basics:**  \n",
        "- **eps**: neighborhood radius; **min_samples**: minimum points to form a dense region.  \n",
        "- Labels: core clusters get 0..C−1; **noise points** are labeled **−1**.  \n",
        "- Pros: finds **arbitrary shapes** and flags noise; no need to choose *k*.  \n",
        "- Cons: sensitive to **scaling** and parameter choice; one global density may struggle when clusters differ in density.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05e6953f",
      "metadata": {
        "id": "05e6953f"
      },
      "outputs": [],
      "source": [
        "\n",
        "def run_dbscan_grid(X, eps_list, ms_list):\n",
        "    rows = []\n",
        "    for e in eps_list:\n",
        "        for m in ms_list:\n",
        "            db = DBSCAN(eps=e, min_samples=m).fit(X)\n",
        "            labels = db.labels_\n",
        "            n_noise = int(np.sum(labels == -1))\n",
        "            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "            sil = np.nan\n",
        "            if n_clusters > 1:\n",
        "                try:\n",
        "                    from sklearn.metrics import silhouette_score\n",
        "                    sil = silhouette_score(X, labels)\n",
        "                except Exception:\n",
        "                    sil = np.nan\n",
        "            rows.append({\"eps\": e, \"min_samples\": m, \"n_clusters\": n_clusters, \"n_noise\": n_noise, \"silhouette\": sil})\n",
        "    return pd.DataFrame(rows).sort_values([\"n_clusters\",\"silhouette\"], ascending=[False, False]).reset_index(drop=True)\n",
        "\n",
        "eps_list = [0.2, 0.3, 0.4, 0.5]\n",
        "ms_list  = [3, 5, 8]\n",
        "\n",
        "grid = run_dbscan_grid(X, eps_list, ms_list)\n",
        "display(grid.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8abe47f6",
      "metadata": {
        "id": "8abe47f6"
      },
      "source": [
        "\n",
        "Pick **two** promising configurations from the table to visualize below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42e7a68b",
      "metadata": {
        "id": "42e7a68b"
      },
      "outputs": [],
      "source": [
        "\n",
        "configs = [\n",
        "    {\"eps\": 0.3, \"min_samples\": 5},\n",
        "    {\"eps\": 0.4, \"min_samples\": 5},\n",
        "]\n",
        "\n",
        "for cfg in configs:\n",
        "    db = DBSCAN(eps=cfg[\"eps\"], min_samples=cfg[\"min_samples\"]).fit(X)\n",
        "    labels = db.labels_\n",
        "    plt.scatter(X_df.iloc[:, ix], X_df.iloc[:, iy], c=labels, s=20)\n",
        "    plt.xlabel(feat_x); plt.ylabel(feat_y)\n",
        "    plt.title(f\"DBSCAN eps={cfg['eps']}, min_samples={cfg['min_samples']}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb101ca6",
      "metadata": {
        "id": "eb101ca6"
      },
      "source": [
        "\n",
        "**Q4:** How did changing **eps** and **min_samples** affect the **number of clusters** and **noise points**?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92cff27a",
      "metadata": {
        "id": "92cff27a"
      },
      "source": [
        "\n",
        "## Part 5: Hierarchical Clustering + Dendrogram\n",
        "\n",
        "\n",
        "- **Agglomerative clustering (Ward linkage)** starts with each point as its own cluster and merges pairs that minimally increase within‑cluster variance.  \n",
        "- A **dendrogram** visualizes merge distances; a **horizontal cut** corresponds to choosing a number of clusters.  \n",
        "- Like K‑Means, Ward linkage uses Euclidean geometry and benefits from scaling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f34fc8a5",
      "metadata": {
        "id": "f34fc8a5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Subsample for dendrogram readability\n",
        "subset_n = 120\n",
        "X_sub = X[:subset_n]\n",
        "\n",
        "# Linkage matrix with Ward's method\n",
        "Z_link = linkage(X_sub, method='ward')\n",
        "\n",
        "# Dendrogram (truncated display)\n",
        "plt.figure(figsize=(8, 4))\n",
        "dendrogram(Z_link, truncate_mode='lastp', p=20, leaf_rotation=30)\n",
        "plt.title(\"Hierarchical clustering dendrogram (truncated)\")\n",
        "plt.xlabel(\"Merged cluster index\"); plt.ylabel(\"Merge distance\")\n",
        "plt.show()\n",
        "\n",
        "# Choose a cut (set number of clusters) and fit Agglomerative on the full set\n",
        "n_clusters = 3  # ← adjust after inspecting dendrogram if desired\n",
        "agg = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
        "labels_agg = agg.fit_predict(X)\n",
        "\n",
        "# Visualize on raw feature axes\n",
        "plt.scatter(X_df.iloc[:, ix], X_df.iloc[:, iy], c=labels_agg, s=20)\n",
        "plt.xlabel(feat_x); plt.ylabel(feat_y)\n",
        "plt.title(f\"Agglomerative (Ward) — n_clusters={n_clusters}\")\n",
        "plt.show()\n",
        "\n",
        "# Optional silhouette for the chosen cut\n",
        "if n_clusters > 1:\n",
        "    sil_agg = silhouette_score(X, labels_agg)\n",
        "    print(f\"Silhouette (Agglomerative, n={n_clusters}): {sil_agg:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b614b709",
      "metadata": {
        "id": "b614b709"
      },
      "source": [
        "\n",
        "**Q5:** Based on the dendrogram, explain how you chose the cut (number of clusters). Compare this hierarchical result to your best K‑Means result.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "NLP",
      "language": "python",
      "name": "nlp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}